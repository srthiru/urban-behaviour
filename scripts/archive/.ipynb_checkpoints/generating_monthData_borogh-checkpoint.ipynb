{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bfe6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab3c76d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'taxi data/taxi_zones_with_latlong.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2004/1217277568.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'taxi data/taxi_zones_with_latlong.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtaxiZone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtaxiZone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtaxiZone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'OBJECTID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Shape_Leng'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Shape_Area'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtaxiZone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\big-data-vis\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\big-data-vis\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\big-data-vis\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\big-data-vis\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\big-data-vis\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\big-data-vis\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\big-data-vis\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\big-data-vis\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'taxi data/taxi_zones_with_latlong.csv'"
     ]
    }
   ],
   "source": [
    "path = 'taxi data/taxi_zones_with_latlong.csv'\n",
    "taxiZone = pd.read_csv(path)\n",
    "\n",
    "taxiZone = taxiZone.drop(columns=['OBJECTID','Shape_Leng', 'Shape_Area'])\n",
    "taxiZone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "561dbb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'taxi data/all data/october.csv'\n",
    "october = pd.read_csv(path)\n",
    "\n",
    "october[\"pickup\"] = pd.to_datetime(october['pickup'])\n",
    "october['pickup'] = october['pickup'].dt.date\n",
    "\n",
    "october[\"dropoff\"] = pd.to_datetime(october['dropoff'])\n",
    "october['dropoff'] = october['dropoff'].dt.date\n",
    "\n",
    "\n",
    "path = 'taxi data/all data/november.csv'\n",
    "november = pd.read_csv(path)\n",
    "november[\"pickup\"] = pd.to_datetime(november['pickup'])\n",
    "november['pickup'] = november['pickup'].dt.date\n",
    "\n",
    "november[\"dropoff\"] = pd.to_datetime(november['dropoff'])\n",
    "november['dropoff'] = november['dropoff'].dt.date\n",
    "\n",
    "\n",
    "path = 'taxi data/all data/december.csv'\n",
    "december = pd.read_csv(path)\n",
    "december[\"pickup\"] = pd.to_datetime(december['pickup'])\n",
    "december['pickup'] = december['pickup'].dt.date\n",
    "\n",
    "december[\"dropoff\"] = pd.to_datetime(december['dropoff'])\n",
    "december['dropoff'] = december['dropoff'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f23cc73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup</th>\n",
       "      <th>dropoff</th>\n",
       "      <th>pickupLocID</th>\n",
       "      <th>dropoffLocID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>255.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>97.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>257.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pickup     dropoff  pickupLocID  dropoffLocID\n",
       "0  2018-10-01  2018-10-01        255.0          97.0\n",
       "1  2018-10-01  2018-10-01         97.0          49.0\n",
       "2  2018-10-01  2018-10-01         25.0         181.0\n",
       "3  2018-10-01  2018-10-01         25.0          40.0\n",
       "4  2018-10-01  2018-10-01         25.0         257.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "october.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c67b2960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the whole month of october data to a json file\n",
    "def getWholeData(allData, month, days):\n",
    "    \n",
    "    loc = taxiZone['LocationID'].to_list()\n",
    "    zo = taxiZone['zone'].to_list()\n",
    "    d = {'zone': zo, 'location': loc}\n",
    "    wholeData = pd.DataFrame(data=d)\n",
    "\n",
    "#     wholeData.head()\n",
    "    for i in range(1, days + 1):\n",
    "        date = datetime.date(2018, month, i)\n",
    "    # #     print(date)\n",
    "        dropdf = allData[(allData.dropoff == date)]\n",
    "        dropdf = dropdf.rename(columns={'dropoff': 'date',\n",
    "                                                       'dropoffLocID': 'LocationID'})\n",
    "        dropdf = dropdf.merge(taxiZone, how='inner', on='LocationID')\n",
    "\n",
    "        df = dropdf['zone'].value_counts().rename_axis('zone').reset_index(name='dropoffCount')\n",
    "\n",
    "        df = df.merge(taxiZone,on='zone', how='inner')\n",
    "\n",
    "        temp = []\n",
    "        for index, row in wholeData.iterrows():\n",
    "            locID = row[\"location\"]\n",
    "\n",
    "            if locID in df['LocationID'].values:\n",
    "                val = df.loc[df['LocationID'] == locID, 'dropoffCount'].to_list()\n",
    "    #             print(df.loc[df['LocationID'] == locID, 'dropoffCount'].to_list())\n",
    "                temp.append(val[0])\n",
    "            else:\n",
    "                temp.append(0)\n",
    "\n",
    "        wholeData[str(date)] = temp\n",
    "        \n",
    "    return wholeData\n",
    "    \n",
    "# wholeData.head()\n",
    "\n",
    "octWhole = getWholeData(october,10, 31)\n",
    "novWhole = getWholeData(november,11, 30)\n",
    "decWhole = getWholeData(december,12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f94621a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone</th>\n",
       "      <th>location</th>\n",
       "      <th>2018-10-01</th>\n",
       "      <th>2018-10-02</th>\n",
       "      <th>2018-10-03</th>\n",
       "      <th>2018-10-04</th>\n",
       "      <th>2018-10-05</th>\n",
       "      <th>2018-10-06</th>\n",
       "      <th>2018-10-07</th>\n",
       "      <th>2018-10-08</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-10-22</th>\n",
       "      <th>2018-10-23</th>\n",
       "      <th>2018-10-24</th>\n",
       "      <th>2018-10-25</th>\n",
       "      <th>2018-10-26</th>\n",
       "      <th>2018-10-27</th>\n",
       "      <th>2018-10-28</th>\n",
       "      <th>2018-10-29</th>\n",
       "      <th>2018-10-30</th>\n",
       "      <th>2018-10-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>4485</td>\n",
       "      <td>3778</td>\n",
       "      <td>4450</td>\n",
       "      <td>5780</td>\n",
       "      <td>5957</td>\n",
       "      <td>3958</td>\n",
       "      <td>5196</td>\n",
       "      <td>5055</td>\n",
       "      <td>...</td>\n",
       "      <td>4652</td>\n",
       "      <td>4089</td>\n",
       "      <td>4396</td>\n",
       "      <td>4918</td>\n",
       "      <td>5027</td>\n",
       "      <td>3100</td>\n",
       "      <td>5805</td>\n",
       "      <td>4976</td>\n",
       "      <td>4071</td>\n",
       "      <td>3817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>950</td>\n",
       "      <td>967</td>\n",
       "      <td>1001</td>\n",
       "      <td>1017</td>\n",
       "      <td>1092</td>\n",
       "      <td>1117</td>\n",
       "      <td>1027</td>\n",
       "      <td>848</td>\n",
       "      <td>...</td>\n",
       "      <td>953</td>\n",
       "      <td>935</td>\n",
       "      <td>998</td>\n",
       "      <td>1032</td>\n",
       "      <td>1168</td>\n",
       "      <td>1210</td>\n",
       "      <td>1055</td>\n",
       "      <td>941</td>\n",
       "      <td>928</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>2635</td>\n",
       "      <td>3101</td>\n",
       "      <td>3122</td>\n",
       "      <td>3400</td>\n",
       "      <td>3875</td>\n",
       "      <td>4932</td>\n",
       "      <td>4123</td>\n",
       "      <td>2774</td>\n",
       "      <td>...</td>\n",
       "      <td>2899</td>\n",
       "      <td>2968</td>\n",
       "      <td>3206</td>\n",
       "      <td>3565</td>\n",
       "      <td>4432</td>\n",
       "      <td>6675</td>\n",
       "      <td>4932</td>\n",
       "      <td>2840</td>\n",
       "      <td>3064</td>\n",
       "      <td>3371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>116</td>\n",
       "      <td>114</td>\n",
       "      <td>140</td>\n",
       "      <td>143</td>\n",
       "      <td>157</td>\n",
       "      <td>141</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "      <td>132</td>\n",
       "      <td>154</td>\n",
       "      <td>171</td>\n",
       "      <td>134</td>\n",
       "      <td>114</td>\n",
       "      <td>105</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      zone  location  2018-10-01  2018-10-02  2018-10-03  \\\n",
       "0           Newark Airport         1        4485        3778        4450   \n",
       "1              Jamaica Bay         2           2           3           1   \n",
       "2  Allerton/Pelham Gardens         3         950         967        1001   \n",
       "3            Alphabet City         4        2635        3101        3122   \n",
       "4            Arden Heights         5         119         116         114   \n",
       "\n",
       "   2018-10-04  2018-10-05  2018-10-06  2018-10-07  2018-10-08  ...  \\\n",
       "0        5780        5957        3958        5196        5055  ...   \n",
       "1           1           0           5           2           0  ...   \n",
       "2        1017        1092        1117        1027         848  ...   \n",
       "3        3400        3875        4932        4123        2774  ...   \n",
       "4         140         143         157         141          98  ...   \n",
       "\n",
       "   2018-10-22  2018-10-23  2018-10-24  2018-10-25  2018-10-26  2018-10-27  \\\n",
       "0        4652        4089        4396        4918        5027        3100   \n",
       "1           0           0           1           0           1           3   \n",
       "2         953         935         998        1032        1168        1210   \n",
       "3        2899        2968        3206        3565        4432        6675   \n",
       "4         110         124         126         132         154         171   \n",
       "\n",
       "   2018-10-28  2018-10-29  2018-10-30  2018-10-31  \n",
       "0        5805        4976        4071        3817  \n",
       "1           0           1           2           1  \n",
       "2        1055         941         928        1083  \n",
       "3        4932        2840        3064        3371  \n",
       "4         134         114         105         146  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "octWhole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8882f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "octWhole.to_csv('taxi data/all data/octoberWhole.csv', index=False)\n",
    "novWhole.to_csv('taxi data/all data/novemberWhole.csv', index=False)\n",
    "decWhole.to_csv('taxi data/all data/decemberWhole.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c563e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDict = []\n",
    "columnList = wholeData.columns.to_list()\n",
    "# print(columnList)\n",
    "for index, row in wholeData.iterrows():\n",
    "\n",
    "#         resultDict[row['location']] = {}\n",
    "    temp = {}\n",
    "    temp[\"zone\"] = row['zone']\n",
    "    temp['location'] = row['location']\n",
    "    temp['values'] = []\n",
    "\n",
    "    for i in range(2,33):\n",
    "        temp['values'].append({'date' : i-1, 'value': row[i]})\n",
    "\n",
    "#     print(temp)\n",
    "            \n",
    "        \n",
    "    resultDict.append(temp)\n",
    "    \n",
    "# print(resultDict)\n",
    "\n",
    "with open('output/whole.json', 'w') as fp:\n",
    "    json.dump(resultDict, fp)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c76c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the whole month of october data to json files\n",
    "for i in range(1,32):\n",
    "    date = datetime.date(2018, 10, i)\n",
    "#     print(date)\n",
    "    dropdf = allData[(allData.dropoff == date)]\n",
    "    dropdf = dropdf.rename(columns={'dropoff': 'date',\n",
    "                                                   'dropoffLocID': 'LocationID'})\n",
    "    dropdf = dropdf.merge(taxiZone, how='inner', on='LocationID')\n",
    "    \n",
    "    df = dropdf['zone'].value_counts().rename_axis('zone').reset_index(name='dropoffCount')\n",
    "\n",
    "    df = df.merge(taxiZone,on='zone', how='inner')\n",
    "    \n",
    "    print(df)\n",
    "\n",
    "#     resultDict = {}\n",
    "#     for index, row in df.iterrows():\n",
    "#         resultDict[row['LocationID']] = row.to_dict()\n",
    "\n",
    "#     with open('output/{}.json'.format(date), 'w') as fp:\n",
    "#         json.dump(resultDict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e73ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting max dropoff for each month\n",
    "resultDict = {}\n",
    "for i in range(1,32):\n",
    "    date = datetime.date(2018, 10, i)\n",
    "#     print(date)\n",
    "    dropdf = allData[(allData.dropoff == date)]\n",
    "    dropdf = dropdf.rename(columns={'dropoff': 'date',\n",
    "                                                   'dropoffLocID': 'LocationID'})\n",
    "    dropdf = dropdf.merge(taxiZone, how='inner', on='LocationID')\n",
    "    \n",
    "    df = dropdf['zone'].value_counts().rename_axis('zone').reset_index(name='dropoffCount')\n",
    "\n",
    "    df = df.merge(taxiZone,on='zone', how='inner')\n",
    "    \n",
    "#     print(df.dropoffCount.max(), df.dropoffCount.min())\n",
    "\n",
    "\n",
    "\n",
    "    resultDict[\"{}\".format(date)] = df.dropoffCount.max()\n",
    "\n",
    "#     with open('output/{}.json'.format(date), 'w') as fp:\n",
    "#         json.dump(resultDict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf374e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open('output/domain.json', 'w') as fp:\n",
    "        json.dump(resultDict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b2eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diwali = datetime.date(2018, 10, 13)\n",
    "\n",
    "\n",
    "diwaliDropoff = allData[(allData.dropoff == diwali)]\n",
    "diwaliDropoff = diwaliDropoff.rename(columns={'dropoff': 'date',\n",
    "                                                   'dropoffLocID': 'LocationID'})\n",
    "print(diwaliDropoff.shape)\n",
    "diwaliDropoff.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b394b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "diwaliDropoff = diwaliDropoff.merge(taxiZone, how='inner', on='LocationID')\n",
    "diwaliDropoff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9774f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "diwaliDropoff['borough'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18916f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "diwaliDropoff['zone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = diwaliDropoff['zone'].value_counts().rename_axis('zone').reset_index(name='dropoffCount')\n",
    "\n",
    "df = df.merge(taxiZone,on='zone', how='inner')\n",
    "df\n",
    "\n",
    "diwaliDict = {}\n",
    "for index, row in df.iterrows():\n",
    "    diwaliDict[row['LocationID']] = row.to_dict()\n",
    "    \n",
    "with open('diwaliDrop.json', 'w') as fp:\n",
    "    json.dump(diwaliDict, fp)\n",
    "\n",
    "# df.to_csv(\"diwaliDrop.csv\", index=False)\n",
    "# df.to_json('diwaliDrop.json', orient = 'records', index = 'false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e58059",
   "metadata": {},
   "outputs": [],
   "source": [
    "pizza = datetime.date(2018, 10, 10)\n",
    "\n",
    "\n",
    "pizza = allData[(allData.dropoff == pizza)]\n",
    "pizza = pizza.rename(columns={'dropoff': 'date',\n",
    "                             'dropoffLocID': 'LocationID'})\n",
    "print(pizza.shape)\n",
    "pizza.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e8d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pizza = pizza.merge(taxiZone, how='inner', on='LocationID')\n",
    "pizza.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee65c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pizza['borough'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde65037",
   "metadata": {},
   "outputs": [],
   "source": [
    "pizza['zone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79062d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDiwali = diwaliDropoff['zone'].value_counts().reset_index()\n",
    "dfDiwali.columns = ['zone', 'count']\n",
    "\n",
    "dfPizza = pizza['zone'].value_counts().reset_index()\n",
    "dfPizza.columns = ['zone', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPizza[dfPizza.zone == 'SoHo']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
